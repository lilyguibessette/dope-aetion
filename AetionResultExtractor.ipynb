{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba056b7a",
   "metadata": {},
   "source": [
    "# How to use the AetionResultExtractor code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d6708d",
   "metadata": {},
   "source": [
    "## Opening Jupyter Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff3dda",
   "metadata": {},
   "source": [
    "These instructions assume you have Python and Jupyter Notebook installed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacfc77",
   "metadata": {},
   "source": [
    "First, open the terminal on your computer. Copy the folder path where this code and your files are saved. Type the following into the terminal to change directory (cd) to this folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a599e6",
   "metadata": {},
   "source": [
    "``` \n",
    "cd \"/User/folder_path/where my files are\"\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a87655",
   "metadata": {},
   "source": [
    "Next, type jupyter notebook into your terminal. This will open an instance of Jupyter Notebook in your web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f576277",
   "metadata": {},
   "source": [
    "``` \n",
    "jupyter notebook\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3bbc60",
   "metadata": {},
   "source": [
    "Now you should be able to see the contents of the folder you originally copied the path for in a Jupyter instance. Click the 'AetionResultExtractor.ipynb' to open this notebook and begin your results extraction!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1416494b",
   "metadata": {},
   "source": [
    "## Running the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03acbf",
   "metadata": {},
   "source": [
    "Run the below huge block of code, do not edit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ecd4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def automate_aetion_results_csv(result_type, exposure, referent, folder_path, file_name, print_on):\n",
    "    file_path = folder_path + file_name\n",
    "    header_patchar = np.array(['tableId', 'tableType', 'analysisId', 'analysisOutcome', 'analysisType', 'analysisLabel', 'cohortType', 'exposureIndex', 'exposureCategoryType', 'exposureCategory', 'variableName', 'variableLevel', 'n', 'pct', 'mean', 'sd', 'median Q2', 'IQR Q1', 'IQR Q3', 'Min', '5%', '10%', '20%', '25%', '30%', '40%', '50%', '60%', '70%', '75%', '80%', '90%', '95%', 'Max', 'std diff'])\n",
    "    header_dichot = np.array(['tableId', 'tableType', 'analysisId', 'analysisOutcome', 'analysisType', 'analysisLabel', 'cohortType', 'exposureIndex', 'exposureCategoryType', 'exposureCategory', 'totalOutcome', 'totalPersonYears', 'exposureCount', 'numOutcomes', 'personYears', 'rateRatio', 'riskRatio','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'])\n",
    "    header_reg_model = np.array(['tableId', 'tableType', 'analysisId', 'analysisOutcome', 'analysisType', 'analysisLabel', 'cohortType', 'effectType', 'modelName', 'effect', 'effectP', 'effectStandardError', 'notes','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'])\n",
    "    headers = np.array([header_patchar,header_dichot,header_reg_model])\n",
    "    results_raw = pd.read_csv(file_path)\n",
    "    results = np.vstack([headers, np.array(results_raw)])\n",
    "    results = df = pd.DataFrame(results)\n",
    "    results.columns = results.iloc[1]\n",
    "    DICHOTOMOUS_EFFECT = results.copy(deep=True)\n",
    "    results.columns = results.iloc[2]\n",
    "    REGRESSION_MODELS = results.copy(deep=True)\n",
    "    results.columns = results.iloc[0]\n",
    "    PATIENT_CHAR = results.copy(deep=True)   \n",
    "    \n",
    "    DICHOTOMOUS_EFFECT = DICHOTOMOUS_EFFECT[DICHOTOMOUS_EFFECT['tableType'] == 'DICHOTOMOUS_EFFECT']\n",
    "    REGRESSION_MODELS = REGRESSION_MODELS[REGRESSION_MODELS['tableType'] == 'REGRESSION_MODELS']\n",
    "    PATIENT_CHAR = PATIENT_CHAR[PATIENT_CHAR['tableType'] != 'REGRESSION_MODELS'] \n",
    "    PATIENT_CHAR = PATIENT_CHAR[PATIENT_CHAR['tableType'] != 'DICHOTOMOUS_EFFECT']\n",
    "    PATIENT_CHAR = PATIENT_CHAR[PATIENT_CHAR['tableType'] != 'tableType']\n",
    "    \n",
    "    if result_type == \"PS\":\n",
    "        rate_csv = DICHOTOMOUS_EFFECT[DICHOTOMOUS_EFFECT['cohortType'] == 'WEIGHTED']\n",
    "        hr_csv = REGRESSION_MODELS[REGRESSION_MODELS['effectType'] == 'PS_WEIGHTED']\n",
    "    else:\n",
    "        rate_csv = DICHOTOMOUS_EFFECT[DICHOTOMOUS_EFFECT['cohortType'] == 'ALL']\n",
    "        hr_csv = REGRESSION_MODELS[REGRESSION_MODELS['effectType'] == 'UNADJUSTED']\n",
    "    \n",
    "    rate_csv = rate_csv.reset_index(drop=True)\n",
    "    hr_csv = hr_csv.reset_index(drop=True)\n",
    "\n",
    "    rate_csv['totalOutcome'] = pd.to_numeric(rate_csv['totalOutcome'])\n",
    "    rate_csv['totalPersonYears'] = pd.to_numeric(rate_csv['totalPersonYears'])\n",
    "    rate_csv['numOutcomes'] = pd.to_numeric(rate_csv['numOutcomes'])\n",
    "    rate_csv['personYears'] = pd.to_numeric(rate_csv['personYears'])\n",
    "\n",
    "    hr_csv['effect'] = pd.to_numeric(hr_csv['effect'])\n",
    "    hr_csv['effectStandardError'] = pd.to_numeric(hr_csv['effectStandardError'])\n",
    "    table = []\n",
    "    for j in range(len(hr_csv)):\n",
    "        #print(j)\n",
    "        i = (j*2)+1\n",
    "        #print(i)\n",
    "        subgroup_hr = hr_csv['analysisLabel'].iloc[j] \n",
    "        outcome_hr = hr_csv['analysisOutcome'].iloc[j]\n",
    "        subgroup_rate = rate_csv['analysisLabel'].iloc[i] \n",
    "        outcome_rate = rate_csv['analysisOutcome'].iloc[i]\n",
    "        ref_out = rate_csv['numOutcomes'].iloc[i-1] \n",
    "        ref_py = rate_csv['personYears'].iloc[i-1]\n",
    "        exp_out = rate_csv['numOutcomes'].iloc[i] \n",
    "        exp_py = rate_csv['personYears'].iloc[i]\n",
    "\n",
    "        ref_rate = rate_csv['numOutcomes'].iloc[i-1] /  rate_csv['personYears'].iloc[i-1]\n",
    "        exp_rate = rate_csv['numOutcomes'].iloc[i] /  rate_csv['personYears'].iloc[i]\n",
    "        p_rate_diff = exp_rate - ref_rate\n",
    "        se_rate_diff = math.sqrt((rate_csv['numOutcomes'].iloc[i-1] /  ((rate_csv['personYears'].iloc[i-1])**2)) + ((rate_csv['numOutcomes'].iloc[i] /  (rate_csv['personYears'].iloc[i])**2)))\n",
    "        z_score = 1.96\n",
    "        lcb_rate = p_rate_diff - z_score* se_rate_diff  #lower limit of the CI\n",
    "        ucb_rate = p_rate_diff + z_score* se_rate_diff  #upper limit of the CI\n",
    "        p_HR = hr_csv['effect'].iloc[j] \n",
    "        lcb = math.log(p_HR) - z_score* hr_csv['effectStandardError'].iloc[j]  #lower limit of the CI\n",
    "        ucb = math.log(p_HR) + z_score* hr_csv['effectStandardError'].iloc[j]  #upper limit of the CI\n",
    "        e_lcb = math.exp(lcb)\n",
    "        e_ucb = math.exp(ucb)\n",
    "        HR = \"{:.2f}\".format(p_HR) + \" (\" + \"{:.2f}\".format(e_lcb)  +\", \"+ \"{:.2f}\".format(e_ucb) + \")\"\n",
    "\n",
    "        if subgroup_rate == subgroup_hr and outcome_rate == outcome_hr:\n",
    "            row = [subgroup_rate, outcome_rate,\"{:.0f}\".format(ref_py), \"{:.0f}\".format(exp_py),ref_out, exp_out, \"{:.2f}\".format(ref_rate*1000), \"{:.2f}\".format(exp_rate*1000), HR]\n",
    "            table.append(row)\n",
    "            if print_on:\n",
    "                print(row)\n",
    "    df_table = pd.DataFrame(table)\n",
    "    df_table.columns = ['Subgroup', 'Outcome', referent + ' '+result_type+' PY', exposure +' '+result_type+' PY', referent +' '+result_type+ ' Events', exposure +' '+result_type+' Events', referent + ' '+ result_type+' Rate', exposure +' '+ result_type+' Rate',  result_type+' Hazard Ratio', result_type+' Rate Difference']\n",
    "    for col in df_table.columns:\n",
    "        df_table[col] = df_table[col].astype(pd.StringDtype())\n",
    "    df_table.to_excel(folder_path+exposure+\"_vs_\"+referent+\"_\"+result_type+\"_Results.xlsx\")\n",
    "    return str(folder_path+exposure+\"_vs_\"+referent+\"_\"+result_type+\"_Results.xlsx\")\n",
    "\n",
    "def automate_aetion_results_xls(result_type, exposure, referent, folder_path, csv_name, print_on):\n",
    "    file_path = folder_path + file_name \n",
    "    result_key = pd.read_excel(file_path, sheet_name=\"Result Key\", header =0)\n",
    "    if result_type == \"PS\":\n",
    "        # captilization was off did not match what is in excel, fixed.\n",
    "        model = 'Propensity score matched'\n",
    "        rate_search = result_key[result_key['Result Name'].str.contains(r'Matched Analysis (Matched on Propensity Score)>Basic Rate Parameters', regex=False)]\n",
    "    elif result_type == \"WEIGHTED\":\n",
    "        # captilization was off did not match what is in excel, fixed.\n",
    "        model = 'Propensity score weighted'\n",
    "        rate_search = result_key[result_key['Result Name'].str.contains(r'Weighted Analysis (IPW/ATE Weights)>Weighted Basic Rate Parameters', regex=False)]\n",
    "    elif result_type == \"HDPS\":\n",
    "        model = 'High-dimensional propensity score matched'\n",
    "        rate_search = result_key[result_key['Result Name'].str.contains(r'Matched Analysis (Matched on High-Dimensional Propensity Score)>Basic Rate Parameters', regex=False)]    \n",
    "    else:\n",
    "        result_type = \"Crude\"\n",
    "        model = 'Unadjusted'\n",
    "        rate_search = result_key[result_key['Result Name'].str.contains(r'Treatment Effect Estimates>Basic Rate Parameters', regex=False)]\n",
    "    hazard_search = result_key[result_key['Result Name'].str.contains(r'Treatment Effect Estimates>Treatment Effects', regex=False)]\n",
    "    \n",
    "    rate_tables = rate_search['Tab'].to_list()\n",
    "    hazard_tables = hazard_search['Tab'].to_list()\n",
    "    #print(hazard_tables)\n",
    "\n",
    "    table = []\n",
    "    for i in range(len(rate_tables)):\n",
    "        #print(i)\n",
    "        sheet_rate = pd.read_excel(file_path, sheet_name= rate_tables[i], header =1)\n",
    "        j=i*2\n",
    "        k=j+1\n",
    "        sheet_xu_rate = pd.read_excel(file_path, sheet_name=hazard_tables[k], header =1)\n",
    "        #print(\"XU\")\n",
    "        #print(k)\n",
    "        #print(sheet_xu_rate)\n",
    "        #print(hazard_tables[k])\n",
    "        sheet_hr = pd.read_excel(file_path, sheet_name=hazard_tables[j], header =1)\n",
    "        #print(\"HR\")\n",
    "        #print(j)\n",
    "        #print(sheet_hr)\n",
    "        #print(hazard_tables[j])\n",
    "        tab_row_rate = result_key[result_key[\"Tab\"] == rate_tables[i]]\n",
    "        tab_row_hr = result_key[result_key[\"Tab\"] == hazard_tables[j]]\n",
    "        type_rate_name = tab_row_rate['PopulationType Label'].iloc[0]\n",
    "        type_hr_name = tab_row_rate['PopulationType Label'].iloc[0]\n",
    "        subgroup_rate = tab_row_rate['Subgroup Name'].iloc[0] \n",
    "        subgroup_hr = tab_row_hr['Subgroup Name'].iloc[0]\n",
    "        outcome_rate = tab_row_rate['Outcome Name'].iloc[0] \n",
    "        outcome_hr = tab_row_rate['Outcome Name'].iloc[0]\n",
    "        #breakpoint()\n",
    "        # this writes over the code for CRUDE type analyses for which these weighted measurements dont exist therefore we need two code blocks for this\n",
    "        ref_n = sheet_rate[sheet_rate['Parameter'] == 'Number of patients'].iloc[0][1]\n",
    "        exp_n = sheet_rate[sheet_rate['Parameter'] == 'Number of patients'].iloc[0][2]   \n",
    "        if result_type == \"WEIGHTED\":\n",
    "            ref_py = sheet_rate[sheet_rate['Parameter'] == 'Number of person-years (unweighted)'].iloc[0][1]\n",
    "            exp_py = sheet_rate[sheet_rate['Parameter'] == 'Number of person-years (unweighted)'].iloc[0][2]\n",
    "            ref_out = sheet_rate[sheet_rate['Parameter'] == 'Number of events'].iloc[0][1]\n",
    "            exp_out = sheet_rate[sheet_rate['Parameter'] == 'Number of events'].iloc[0][2]\n",
    "            ref_rate = sheet_rate[sheet_rate['Parameter'] == 'Weighted rate per 1,000 person-years (95% CI)'].iloc[0][1]\n",
    "            exp_rate = sheet_rate[sheet_rate['Parameter'] == 'Weighted rate per 1,000 person-years (95% CI)'].iloc[0][2]\n",
    "            \n",
    "        else:\n",
    "            ref_py = sheet_rate[sheet_rate['Parameter'] == 'Number of person-years'].iloc[0][1]\n",
    "            exp_py = sheet_rate[sheet_rate['Parameter'] == 'Number of person-years'].iloc[0][2]\n",
    "            ref_out = sheet_rate[sheet_rate['Parameter'] == 'Number of events'].iloc[0][1]\n",
    "            exp_out = sheet_rate[sheet_rate['Parameter'] == 'Number of events'].iloc[0][2]\n",
    "            ref_rate = sheet_rate[sheet_rate['Parameter'] == 'Rate per 1,000 person-years'].iloc[0][1]\n",
    "            exp_rate = sheet_rate[sheet_rate['Parameter'] == 'Rate per 1,000 person-years'].iloc[0][2]\n",
    "            rate_diff = sheet_rate[sheet_rate['Parameter'] == 'Rate difference per 1,000 person-years (vs. referent; 95% CI)'].iloc[0][2]      \n",
    "            # xu_rate_diff = sheet_xu_rate[sheet_xu_rate['Model'] == model]['Estimate (per 1000 Person-years)'].iloc[0]\n",
    "        #if sheet_hr.columns[1] =='Estimate (per 1000 Person-years)':\n",
    "        #    sheet_hr = pd.read_excel(file_path, sheet_name=hazard_tables[i+1], header =1)\n",
    "        #    PS_HR = sheet_hr[sheet_hr['Model'] == model]['Hazard Ratio'].iloc[0]\n",
    "        #else:\n",
    "        try:\n",
    "            PS_HR = sheet_hr[sheet_hr['Model'] == model]['Hazard Ratio'].iloc[0]\n",
    "        except:\n",
    "            PS_HR = \"NA\"\n",
    "            \n",
    "        if type_rate_name == type_hr_name:\n",
    "            if result_type == \"WEIGHTED\":\n",
    "                row = [subgroup_rate, outcome_rate,ref_n, exp_n, ref_py, exp_py, ref_out, exp_out, ref_rate, exp_rate, PS_HR]\n",
    "            else:\n",
    "                row = [subgroup_rate, outcome_rate,ref_n, exp_n, ref_py, exp_py, ref_out, exp_out, ref_rate, exp_rate, PS_HR, rate_diff]\n",
    "            #row = [subgroup_rate, outcome_rate,\"{:.0f}\".format(ref_py), \"{:.0f}\".format(exp_py),ref_out, exp_out, \"{:.2f}\".format(ref_rate), \"{:.2f}\".format(exp_rate), PS_HR]\n",
    "            table.append(row)\n",
    "            if print_on:\n",
    "                print(row)\n",
    "    df_table = pd.DataFrame(table)\n",
    "    if result_type == \"WEIGHTED\":\n",
    "        df_table.columns = ['Subgroup', 'Outcome', referent + ' '+result_type+' N', exposure +' '+result_type+' N', referent + ' '+result_type+' PY', exposure +' '+result_type+' PY', referent +' '+result_type+ ' Events', exposure +' '+result_type+' Events', referent + ' '+ result_type+' Rate', exposure +' '+ result_type+' Rate',  result_type+' Hazard Ratio' ]#, result_type+' Rate Difference']\n",
    "    else:\n",
    "        df_table.columns = ['Subgroup', 'Outcome', referent + ' '+result_type+' N', exposure +' '+result_type+' N', referent + ' '+result_type+' PY', exposure +' '+result_type+' PY', referent +' '+result_type+ ' Events', exposure +' '+result_type+' Events', referent + ' '+ result_type+' Rate', exposure +' '+ result_type+' Rate',  result_type+' Hazard Ratio' , result_type+' Rate Difference']\n",
    "    for col in df_table.columns:\n",
    "        df_table[col] = df_table[col].astype(pd.StringDtype())\n",
    "    df_table.to_excel(folder_path+exposure+\"_vs_\"+referent+\"_\"+result_type+\"_Results.xlsx\")\n",
    "    return str(folder_path+exposure+\"_vs_\"+referent+\"_\"+result_type+\"_Results.xlsx\")\n",
    "\n",
    "def automate_aetion_results(aetion_version, result_type, exposure, referent, folder_path, file_name, print_on):\n",
    "    if aetion_version == \"CSV\":\n",
    "        result_file_name = automate_aetion_results_csv(result_type, exposure, referent, folder_path, file_name, print_on)\n",
    "    else:\n",
    "        result_file_name = automate_aetion_results_xls(result_type, exposure, referent, folder_path, file_name, print_on)\n",
    "    print(\"Output completed. Saved as: \"+result_file_name)\n",
    "\n",
    "def prompt_inputs():\n",
    "    aetion_version = \"\"  # \"CSV\" or \"XLS\"\n",
    "    result_type = \"\"    # \"Crude\" or \"PS\"\n",
    "    exposure = \"\" # Type Exposure Name Here\n",
    "    referent = \"\" # Type Reference Name Here\n",
    "    folder_path = \" \" # Type Folder Path\n",
    "    file_name = \"\" # Type File Name \".csv\" or \".xls\" types\n",
    "    print_on = \"\"\n",
    "    while (aetion_version != \"CSV\") and (aetion_version != \"XLS\"):\n",
    "        aetion_version = input(\"Enter aetion_version 'CSV' or 'XLS': \")  # \"CSV\" or \"XLS\"\n",
    "    while (result_type != \"Crude\") and (result_type != \"PS\"):\n",
    "        result_type = input(\"Enter result_type 'Crude' or 'PS': \")  # \"Crude\" or \"PS\"\n",
    "    while exposure == \"\":\n",
    "        exposure = input(\"Enter Exposure Name Here: \")\n",
    "    while referent == \"\":\n",
    "        referent = input(\"Enter Reference Name Here: \")\n",
    "    while folder_path == \" \":\n",
    "        print(\"If program is ran in same folder as result file, press enter.\")\n",
    "        folder_path = input(\"Enter Folder Path Here: \")\n",
    "    while file_name == \"\":\n",
    "        file_name = input(\"Enter File Name with '.csv' or '.xls' ending: \")\n",
    "    while (print_on != \"On\") and (print_on != \"Off\"):\n",
    "        print(\"About print_on option:\")\n",
    "        print(\"'On': To see your results as they are generated\") \n",
    "        print(\"'Off': To suppress the print statements (runs faster)\")\n",
    "        print_on = input(\"Enter 'On' or 'Off' for print option: \" )\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Aetion Result File Version: \"+aetion_version)\n",
    "    print(\"Result Type: \"+result_type)\n",
    "    print(\"Exposure: \" + exposure)\n",
    "    print(\"Reference: \" + referent)\n",
    "    print(\"Print Option: \" + print_on)\n",
    "    if print_on == \"On\":\n",
    "        print_on = True\n",
    "    else:\n",
    "        print_on = False\n",
    "    print(\"This will be your file path that the program will try to open the file from:\")\n",
    "    file_path = folder_path + file_name \n",
    "    print(file_path)\n",
    "    correct = input(\"Are these all options correct? Y/N: \")\n",
    "    if correct.lower() != \"Y\".lower():\n",
    "        prompt_inputs()\n",
    "    print(\"------------- Program Running -------------\")\n",
    "    return aetion_version, result_type, exposure, referent, folder_path, file_name, print_on\n",
    "\n",
    "\n",
    "def automate_aetion_results_prompted():\n",
    "    aetion_version, result_type, exposure, referent, folder_path, file_name, print_on = prompt_inputs()\n",
    "    automate_aetion_results(aetion_version, result_type, exposure, referent, folder_path, file_name, print_on)\n",
    "\n",
    "\n",
    "def auto_check_std_diff_conv(folder_path, file_name, std_diff_level, xu_analysis):\n",
    "    file_path = folder_path + file_name\n",
    "    result_key = pd.read_excel(file_path, sheet_name=\"Result Key\", header =0)\n",
    "    search_ps_model = result_key[result_key['Result Name'].str.contains(r'PS Model', regex=False)]\n",
    "    search_cox = result_key[result_key['Result Name'].str.contains(r'Cox Regression Diagnostics', regex=False)]\n",
    "    if xu_analysis:\n",
    "        search_xu = result_key[result_key['Result Name'].str.contains(r'Xu Regression Diagnostics', regex=False)]\n",
    "        xu_tables = search_xu['Tab'].to_list()\n",
    "    search_confounder_diff = result_key[result_key['ResultComponentType'].str.contains(r'CONFOUNDER_DIFFERENCE', regex=False)]\n",
    "    ps_model_tables = search_ps_model['Tab'].to_list()\n",
    "    cox_tables = search_cox['Tab'].to_list()\n",
    "    conf_diff_tables = search_confounder_diff['Tab'].to_list()\n",
    "    subgroup_list = search_confounder_diff['Subgroup Name'].to_list()\n",
    "    outcome_list = search_confounder_diff['Outcome Name'].to_list()\n",
    "    result_list = search_confounder_diff['Result Name'].to_list()\n",
    "    table = []\n",
    "    for i in range(len(conf_diff_tables)):\n",
    "        #print(conf_diff_tables[i])\n",
    "        conf_diff_sheet = pd.read_excel(file_path, sheet_name= conf_diff_tables[i], header =1)\n",
    "        conf_diff_sheet = conf_diff_sheet[conf_diff_sheet[\"Abs. Std. Diff. (Matched)\"] != \"-\"]\n",
    "        conf_diff_errors = conf_diff_sheet[conf_diff_sheet[\"Abs. Std. Diff. (Matched)\"] > std_diff_level]\n",
    "        if conf_diff_errors.empty:\n",
    "            conf_diff_status = 0\n",
    "            conf_diff_variables = \"NA\"\n",
    "        else:\n",
    "            conf_diff_variables = str(list(conf_diff_errors['Variable']))\n",
    "            conf_diff_status = len(conf_diff_errors['Variable'])\n",
    "        cox_sheet = pd.read_excel(file_path, sheet_name= cox_tables[i], header =1)\n",
    "        cox_status =  cox_sheet['Value'][1]\n",
    "        if xu_analysis:\n",
    "            xu_sheet = pd.read_excel(file_path, sheet_name= xu_tables[i], header =1)\n",
    "            xu_status = xu_sheet['Value'][1]\n",
    "        else:\n",
    "            xu_status = \"NA\"\n",
    "        ps_model_sheet = pd.read_excel(file_path, sheet_name= ps_model_tables[i], header =1)\n",
    "        ps_model_errors = ps_model_sheet[ps_model_sheet[\"Odds Ratio\"].str.contains(r'<|>|∞|N/A')]\n",
    "        if ps_model_errors.empty:\n",
    "            ps_model_status = 0\n",
    "            ps_model_variables = \"NA\"\n",
    "            ps_model_odds = \"NA\"\n",
    "        else:\n",
    "            ps_model_variables = str(list(ps_model_errors['Variable']))\n",
    "            ps_model_odds = str(list(ps_model_errors['Odds Ratio']))\n",
    "            ps_model_status = len(ps_model_errors['Variable'])\n",
    "        row = [result_list[i], outcome_list[i], subgroup_list[i], conf_diff_status, conf_diff_variables, cox_status, xu_status, ps_model_status, ps_model_variables, ps_model_odds]\n",
    "        table.append(row)\n",
    "    df_table = pd.DataFrame(table)\n",
    "    df_table.columns = ['RESULT', 'OUTCOME', 'SUBGROUP', \"Num Abs. Std. Diff. (Matched) >\"+str(std_diff_level), \"Variables with >\"+str(std_diff_level), \"COX Convergence Status\", \"XU Convergence Status\", \"PS Model Num Extreme ORs\", \"PS Model Flagged Variables\", \"PS Model Flagged ORs\"]\n",
    "    df_table.to_excel(folder_path+\"CONVERGENCE_CHECK_\"+str(std_diff_level)+\"_Results_\"+file_name+\"x\")\n",
    "    print(\"Results saved in: \" + folder_path)\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e820c47",
   "metadata": {},
   "source": [
    "### Set a folder path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58f199",
   "metadata": {},
   "source": [
    "This is where your current Aetion .xls result files are stored and where you want your final results to be saved to. Make sure that your folder path ends with a '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77349bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/wherever my file is saved/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b447c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "# folder_path = \"/Users/someone/Dropbox (Partners HealthCare)/foldername/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6844cc",
   "metadata": {},
   "source": [
    "### Name your analysis and the file names that you'll be extracting from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2afc0633",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = \"CMS_HIV_Primary\" # Name your analysis\n",
    "warf_file = \"12345.xls\" # file to extract from\n",
    "other_file = \"67890.xls\" # file to extract from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3680578",
   "metadata": {},
   "source": [
    "## auto_check_std_diff_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f9c7c5",
   "metadata": {},
   "source": [
    "These function calls will produce a file labeled \"CONVERGENCE_CHECK\" which will check how many variables have an absolute std. difference greater than the threshold set by the value of std_diff_level (i.e. > 0.1). The True/False flag signifies whether you would like the Xu Regression Diagnostics as well as the Cox Regression Diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bdcf29",
   "metadata": {},
   "source": [
    "##### auto_check_std_diff_conv arguments:\n",
    "\n",
    "folder_path = folder path that file_name is in\n",
    "\n",
    "file_name = name of file\n",
    "\n",
    "std_diff_level = threshold to evaluate the absolute std. differences at\n",
    "\n",
    "xu_analysis = whether or not you ran the Xu analysis and want those regression diagnositcs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "141d5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = specified above\n",
    "# warf_file = specified above\n",
    "# std_diff_level = directly specified in the function call below\n",
    "# xu_analysis = directly specified in the function call below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b71a05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: /Users/lg436/Library/Mobile Documents/com~apple~CloudDocs/BWH_DoPE/Claire_python_update/\n"
     ]
    }
   ],
   "source": [
    "auto_check_std_diff_conv(folder_path, warf_file, 0.1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba1682",
   "metadata": {},
   "source": [
    "If it runs successfully, you should see a message output: \"Results saved in:\" followed by your folder path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a6468",
   "metadata": {},
   "source": [
    "## automate_aetion_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c93b47",
   "metadata": {},
   "source": [
    "This is the main function call that will extract the desired results. Please see below for argument specifications and be careful to use only the options available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d87ef89",
   "metadata": {},
   "source": [
    "##### auto_check_std_diff_conv arguments:\n",
    "\n",
    "*aetion_version* = Options are \"XLS\" or \"CSV\" - Must exactly match either of these inputs. This tells the function which file type it will be extracting from. Older versions of Aetion may output as CSV's, but the main file type now is XLS.\n",
    "\n",
    "*result_type* = Options are  \"Crude\", \"PS\", \"HDPS\", and \"WEIGHTED\" -  Must exactly match either of these inputs or else you may extract results that you did not intend to. \n",
    "\n",
    "*exposure* = A short name for the Exposure group you specified in the Aetion analysis.This is only for labeling results and not used to search through the result file at all.\n",
    "\n",
    "*referent* = A short name for the Referent group you specified in the Aetion analysis. This is only for labeling results and not used to search through the result file at all.\n",
    "\n",
    "*folder_path* = This should be the folder path that file_name is stored in - Make sure this ends in a '/'\n",
    "\n",
    "*file_name* = This should be the name of the file to extract information from - Can be a file you specified above (i.e. warf_file) or the name of the file \"12345.xls\"\n",
    "\n",
    "*print_on* = This tells the function whether or not you want to print intermediate outputs to the Jupyter notebook screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b57cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "aetion_version=\"XLS\" # options are CSV or XLS\n",
    "result_type=\"Crude\" # options are only \"Crude\", \"PS\", \"HDPS\", and \"WEIGHTED\" - these must be typed EXACTLY as this\n",
    "exposure=\"Warfarin\" # a label for your exposure group\n",
    "referent=\"Apixaban\" # a label for your referent group\n",
    "file_name=warf_file # can be a file you specified above or the file name itself i.e. 12345.xls\n",
    "print_on=False # whether or not to print intermediate outputs as the function runs to the Jupyter notebook screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c111c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output completed. Saved as: /Users/lg436/Library/Mobile Documents/com~apple~CloudDocs/BWH_DoPE/Claire_python_update/Warfarin_vs_Apixaban_Crude_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "automate_aetion_results(aetion_version, \n",
    "                        result_type, \n",
    "                        exposure, referent, \n",
    "                        folder_path, \n",
    "                        file_name, \n",
    "                        print_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78eaadb",
   "metadata": {},
   "source": [
    "If it runs successfully, you should see a message output: \"Output completed. Saved as: \" followed by your folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aetion_version=\"XLS\" # specified above, no need to re-run unless changing\n",
    "# result_type=\"Crude\" # we change this below for our \"PS\" analysis\n",
    "# exposure=\"Warfarin\" # specified above, no need to re-run unless changing\n",
    "# referent=\"Apixaban\" # specified above, no need to re-run unless changing\n",
    "# folder_path = specified above, no need to re-run unless changing\n",
    "# file_name=warf_file # specified above, no need to re-run unless changing\n",
    "# print_on=False # specified above, no need to re-run unless changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ad7a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output completed. Saved as: /Users/lg436/Library/Mobile Documents/com~apple~CloudDocs/BWH_DoPE/Claire_python_update/Warfarin_vs_Apixaban_PS_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "result_type=\"PS\" # Note we change this to now get the PS results.                 \n",
    "automate_aetion_results(aetion_version, \n",
    "                        result_type, \n",
    "                        exposure, referent, \n",
    "                        folder_path, \n",
    "                        file_name, \n",
    "                        print_on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d582d25a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output completed. Saved as: /Users/lg436/Library/Mobile Documents/com~apple~CloudDocs/BWH_DoPE/Claire_python_update/Warfarin_vs_Apixaban_WEIGHTED_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "result_type=\"WEIGHTED\" # Note we change this to now get the WEIGHTED results.                 \n",
    "automate_aetion_results(aetion_version, \n",
    "                        result_type, \n",
    "                        exposure, referent, \n",
    "                        folder_path, \n",
    "                        file_name, \n",
    "                        print_on)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5680a405",
   "metadata": {},
   "source": [
    "### Then if you need to change to another comparator or for a sensitivity analysis, just change your parameters!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aetion_version=\"XLS\" # options are CSV or XLS\n",
    "result_type=\"Crude\" # options are only \"Crude\", \"PS\", and \"WEIGHTED\" - these must be typed EXACTLY as this\n",
    "exposure=\"OtherExposure\" # a label for your exposure group\n",
    "referent=\"OtherReferent\" # a label for your referent group\n",
    "file_name=other_file # example\n",
    "file_name=\"67890.xls\" # can be a file you specified above or the file name itself i.e. 12345.xls\n",
    "print_on=False # whether or not to print intermediate outputs as the function runs to the Jupyter notebook screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aac1b0b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output completed. Saved as: /Users/lg436/Library/Mobile Documents/com~apple~CloudDocs/BWH_DoPE/Claire_python_update/Warfarin_Sens_vs_Apixaban_Crude_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "automate_aetion_results(aetion_version, \n",
    "                        result_type, \n",
    "                        exposure, referent, \n",
    "                        folder_path, \n",
    "                        file_name, \n",
    "                        print_on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4fe797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output completed. Saved as: /Users/lg436/Library/Mobile Documents/com~apple~CloudDocs/BWH_DoPE/Claire_python_update/Warfarin_Sens_vs_Apixaban_PS_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "                        result_type=\"PS\"\n",
    "automate_aetion_results(aetion_version, \n",
    "                        result_type, \n",
    "                        exposure, referent, \n",
    "                        folder_path, \n",
    "                        file_name, \n",
    "                        print_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61469867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output completed. Saved as: /Users/lg436/Library/Mobile Documents/com~apple~CloudDocs/BWH_DoPE/Claire_python_update/Warfarin_Sens_vs_Apixaban_WEIGHTED_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "                        result_type=\"WEIGHTED\"\n",
    "automate_aetion_results(aetion_version, \n",
    "                        result_type, \n",
    "                        exposure, referent, \n",
    "                        folder_path, \n",
    "                        file_name, \n",
    "                        print_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146570ad",
   "metadata": {},
   "source": [
    "# Combining all your output into one Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8793e",
   "metadata": {},
   "source": [
    "This code can be used to combine all the output files to one excel file with multiple sheets. To edit simply change the .xlsx file names to the order that you want to combine and add names for each sheet you're adding. The first set chunk of lines (pd.read_excel) will read in the specified files and the .to_excel lines will add each file into a new sheet with the specified sheet name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2174a252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lg436/opt/anaconda3/lib/python3.8/site-packages/xlsxwriter/workbook.py:336: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "writer = pd.ExcelWriter(folder_path+analysis+\".xlsx\")\n",
    "\n",
    "sheet_1 =pd.read_excel(folder_path+'Warfarin_vs_Apixaban_Crude_Results.xlsx')\n",
    "sheet_2 =pd.read_excel(folder_path+'Warfarin_vs_Apixaban_PS_Results.xlsx')\n",
    "sheet_3 =pd.read_excel(folder_path+'Warfarin_vs_Apixaban_WEIGHTED_Results.xlsx')\n",
    "sheet_4 =pd.read_excel(folder_path+'OtherExposure_vs_OtherReferent_Crude_Results.xlsx')\n",
    "sheet_5 =pd.read_excel(folder_path+'OtherExposure_vs_OtherReferent_PS_Results.xlsx')\n",
    "sheet_6 =pd.read_excel(folder_path+'OtherExposure_vs_OtherReferentn_WEIGHTED_Results.xlsx')\n",
    "\n",
    "sheet_1.to_excel(writer, sheet_name = 'Warf_vs_Apixaban_Crude', index=False)\n",
    "sheet_2.to_excel(writer, sheet_name = 'Warf_vs_Apixaban_PS', index=False)\n",
    "sheet_3.to_excel(writer, sheet_name = 'Warf_vs_Apixaban_Weighted', index=False)\n",
    "sheet_4.to_excel(writer, sheet_name = 'OtherExposure_vs_OtherReferent_Crude', index=False)\n",
    "sheet_5.to_excel(writer, sheet_name = 'OtherExposure_vs_OtherReferent_PS', index=False)\n",
    "sheet_6.to_excel(writer, sheet_name = 'OtherExposure_vs_OtherReferent_Weighted', index=False)\n",
    "\n",
    "writer.save()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
